---
layout: project
title: Engineering Ethics Final
image: /assets/images/function-graph.png
description: Final report for MAE 4300 (Engineering Ethics)
---

# 

In 2018 and 2019, Boeing saw two crashes of the 737 Max with large numbers of casualties. These two crashes led to the 737 Max getting grounded until late 2020. At the center of the crisis is the Maneuvering Characteristics Augmentaiton System (MCAS), which was a system introduced to automatically adjust the horizontal stabilizer of the airfract to prevent stalls at high angles of attack. While MCAS was intended to improve the safety of the plane, the decisions made during its design, certification, and deployment ultimately contrinbuted to the loss of life in the incidents named above. This case highlights systemic ethical failures driven by cost, schedule pressure, regulatory conflicts of interested and a lack of transparency.

There are five ethical questions pertinent to the 737 Max case that are explored here. 

- Should Boeing have prioritized training costs and schedule slips overadequate pilot preparation?
- Should the FAA have delegated regulatory authority to Boeing?
- Should engineers blindly defer to leadership?
- Should Boeing have disclosed design changes to airlines and the public?
- Should whistleblower protections be enforced more explicitly?

There are several facts of the case that are essential to understanding the ethical context in which this incident took place. In order to account for larger, heavier engines, Boeing mounted them further forward on the wing compareed to previous 737 models. This change altered how the plane handled, especially increasing the tendency of the nose to pitch at high angles of attack. This is what MCAS was introduced to counteract. MCAS only relied on data from one single angle of attack sensor, which created a lack of reduncancy in a system that was safety critical. Boeing incorrectly classified MCAS as a modification to an existing system rather than a new system, which reduced the scrutiny on it during certification. Additionally, Boeing determined that the failure of the single angle of attack sensor was in fact catastrophic, but proceeded with the design anyway. At the individual decision-making level, Boeing probably assumed the probability of such a failure was very low, and that the pilots would respond appropriately if MCAS ever malfunctioned. In order to further skirt regulatory authority, they removed references of MCAS from the flight manual, so pilots were not even aware of it when they flew the plane. Despite this, the FAA accepted Boeing’s human factors analysis and deemed MCAS as not needing any further oversight. Organizationally, the FAA relied heavily on information procided by Boeing and delegated portions of the certification process back to them. This probably created the gaps in regulatory review that allows the MCAS miss to slip through.

While not all internal decision-making details are publicaly known, several reasonable assumptions can be made based on the evidence available. Boeing was likely under significant pressure to compete with rival aircraft that were being released at the time, and as such, felt that they needed to minimize training requirements in order to get it on the market sooner. Boeing’s upper management likely prioritized cost control and schedule adherence, and discouraged actions that could delay market entry, even if it sacrificed some level of safety. It is hard to believe that design reviews internally did not catch any of the safety concerns with MCAS, as FMEA is a standard practice in engineer. Text messages between people employed by Boeing, like Mark Forkner, identified egregious safety concerns with the system, but those concerns were not adequately addressed.

Returning to the questions outlined above, Boeing faced a clear ethical choice between minimizing the schedule risk of the 737 Max and ensuring pilot safety by taking the time to train them properly. By hiding MCAS from them, Boeing did likely reduce costs and timeline issues in the short term. However, this decision left pilots unprepared to respond to MCAS failures, and ultimately, two planes full of civilians were lost.

The FAA’s delegation of cetification authority to Boeing is an example of a conflict of interest. While it is reasonable to assume that Boeing engineers are knowledgeable about the systems they designed, it is also reasonable to assume that they were biased, either by their own drive to push their parts out successfully or by pressure from their superiors. Independent oversight is essential in safety-crtitical industries like aerospace for this reason. 

Based on Mark Forkner’s text messages, it seems like engineers involved in the design of MCAS did not sufficiently challenge the decisions that their leadership was making, which including increasing the aggressiveness of the system even with the single point of failure still present. While any hierarchical structure like that can discourage disagreeing with superiors, engineers retain a professional obligation to bring up safety concerns when they do occur. 

Boeing’s decision to conceal MCAS changes from airlines and pilots, especially given the impact the system ended up having on safe flight, definitely eroded transparency and trust in the company. While there is definitely design information at Boeing that is proprietary, export controlled, or classified, changes that affect aircraft handling are directly relevant to pilot safety, and should have been disclosed when the plane was released. While the FAA and Boeing may rely on predefined standards and documentation for defining safety, the general public will feel unsafe given the previous tragedies that have occurred during Boeing 737 Max flights because of the MCAS oversight. 

The 737 Max case demonstrates how seemingly small and reactive design decisions can become large ethical concerns. Boeing’s prioritization of schedule and cost of training pilots on MCAS, as well as the internal culture that prevented people with concerns from coming forward, ultimately sacrificed the safety of the people onboard the 737 Max, which is a large ethical failing. Upholding safety as a paramount principle in the design of critical systems like planes helps maintain the public’s trust and prevent future tragedies.
